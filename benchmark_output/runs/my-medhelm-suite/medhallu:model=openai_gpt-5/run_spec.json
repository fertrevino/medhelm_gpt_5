{
  "name": "medhallu:model=openai_gpt-5",
  "scenario_spec": {
    "class_name": "helm.benchmark.scenarios.medhallu_scenario.MedHalluScenario",
    "args": {}
  },
  "adapter_spec": {
    "method": "generation",
    "global_prefix": "",
    "global_suffix": "",
    "instructions": "You are an AI assistant with extensive knowledge in the field of medicine. I want you act as an answer judge. Given a question and an answer, your objective is to determine if the provided answer contains non-factual or hallucinated information. You SHOULD give your judgement based on the following hallucination types and the world knowledge.\n\nYou are trying to determine if there is a factual contradiction between the answer and the world knowledge. Some information in the answer might be fabricated. Answer '0' if the answer is factual and '1' if the answer is hallucinated. You can categorize the answer as hallucinated if it falls in either of the category:\nType: Misinterpretation of #Question#: These are hallucinated answers that misunderstands the question, leading to an off-topic or irrelevant response.\nType: Incomplete Information: These are hallucinated answers that Point out what is not true without providing correct information.\nType: Mechanism and Pathway Misattribution - These are hallucinated answer that falsely attribution of biological mechanisms, molecular pathways, or disease processes that contradicts established medical knowledge\nType: Methodological and Evidence Fabrication - Inventing false research methods, statistical data, or specific clinical outcomes\n\nDo not return anything else, just the answer.\nReturn just an integer value, '0' if the answer is factual and '1' if the answer is hallucinated. No letter or word, just the integer value.\n",
    "input_prefix": "",
    "input_suffix": "\n",
    "reference_prefix": "A. ",
    "reference_suffix": "\n",
    "chain_of_thought_prefix": "",
    "chain_of_thought_suffix": "\n",
    "output_prefix": "Return just an integer value, '0' if the answer is factual and '1' if the answer is hallucinated.\nNo letter or word, just the integer value.\n\nYour Judgment: ",
    "output_suffix": "\n",
    "instance_prefix": "\n",
    "substitutions": [],
    "max_train_instances": 0,
    "max_eval_instances": 100,
    "num_outputs": 1,
    "num_train_trials": 1,
    "num_trials": 1,
    "sample_train": true,
    "model_deployment": "openai/gpt-5",
    "model": "openai/gpt-5",
    "temperature": 0.0,
    "max_tokens": 5,
    "stop_sequences": [],
    "multi_label": false
  },
  "metric_specs": [
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
      "args": {
        "names": [
          "exact_match",
          "quasi_exact_match",
          "prefix_exact_match",
          "quasi_prefix_exact_match"
        ]
      }
    },
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
      "args": {}
    },
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
      "args": {}
    }
  ],
  "data_augmenter_spec": {
    "perturbation_specs": [],
    "should_augment_train_instances": false,
    "should_include_original_train": false,
    "should_skip_unchanged_train": false,
    "should_augment_eval_instances": false,
    "should_include_original_eval": false,
    "should_skip_unchanged_eval": false,
    "seeds_per_instance": 1
  },
  "groups": [
    "medhallu"
  ]
}