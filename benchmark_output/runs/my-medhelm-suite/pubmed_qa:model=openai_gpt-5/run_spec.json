{
  "name": "pubmed_qa:model=openai_gpt-5",
  "scenario_spec": {
    "class_name": "helm.benchmark.scenarios.pubmed_qa_scenario.PubMedQAScenario",
    "args": {}
  },
  "adapter_spec": {
    "method": "multiple_choice_joint",
    "global_prefix": "",
    "global_suffix": "",
    "instructions": "Answer A for yes, B for no or C for maybe. Do not include any explanation or additional text. Output only the letter on a single line.\n",
    "input_prefix": "Question: ",
    "input_suffix": "\n",
    "reference_prefix": "A. ",
    "reference_suffix": "\n",
    "chain_of_thought_prefix": "",
    "chain_of_thought_suffix": "\n",
    "output_prefix": "Answer: ",
    "output_suffix": "\n",
    "instance_prefix": "\n",
    "substitutions": [],
    "max_train_instances": 0,
    "max_eval_instances": 100,
    "num_outputs": 5,
    "num_train_trials": 1,
    "num_trials": 1,
    "sample_train": true,
    "model_deployment": "openai/gpt-5",
    "model": "openai/gpt-5",
    "temperature": 0.0,
    "max_tokens": 1,
    "stop_sequences": [
      "\n"
    ],
    "multi_label": false
  },
  "metric_specs": [
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
      "args": {
        "names": [
          "exact_match",
          "quasi_exact_match",
          "prefix_exact_match",
          "quasi_prefix_exact_match"
        ]
      }
    },
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
      "args": {}
    },
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
      "args": {}
    }
  ],
  "data_augmenter_spec": {
    "perturbation_specs": [],
    "should_augment_train_instances": false,
    "should_include_original_train": false,
    "should_skip_unchanged_train": false,
    "should_augment_eval_instances": false,
    "should_include_original_eval": false,
    "should_skip_unchanged_eval": false,
    "seeds_per_instance": 1
  },
  "groups": [
    "pubmed_qa"
  ]
}